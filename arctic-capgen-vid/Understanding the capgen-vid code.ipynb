{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing and understanding the capgen-vid code, mostly the code of the decoder where the LSTM is connected to generate descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import numpy as np\n",
    "\n",
    "import os, sys, socket, shutil\n",
    "import time\n",
    "\n",
    "from config import config\n",
    "from jobman import DD, expand\n",
    "import common\n",
    "import model_attention\n",
    "\n",
    "import theano\n",
    "import theano.tensor as tensor\n",
    "import theano.tensor as T\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "\n",
    "\n",
    "import copy\n",
    "import warnings\n",
    "from collections import OrderedDict\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy import optimize, stats\n",
    "\n",
    "import data_engine\n",
    "import metrics\n",
    "import common\n",
    "\n",
    "\n",
    "from common import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the CAP.pkl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'ascii' codec can't decode byte 0xe0 in position 0: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-915e4efa975d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             \u001b[0mobjects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopenfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0xe0 in position 0: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "objects = []\n",
    "with(open(\"youtube2text_iccv15/worddict.pkl\", \"rb\")) as openfile:\n",
    "    while True:\n",
    "        try:\n",
    "            objects.append(pickle.load(openfile))\n",
    "        except EOFError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['vid117_17',\n",
       "  'vid523_28',\n",
       "  'vid262_27',\n",
       "  'vid57_47',\n",
       "  'vid1101_20',\n",
       "  'vid941_17',\n",
       "  'vid255_4',\n",
       "  'vid200_19',\n",
       "  'vid838_7',\n",
       "  'vid914_12',\n",
       "  'vid854_42',\n",
       "  'vid163_8',\n",
       "  'vid325_40',\n",
       "  'vid487_26',\n",
       "  'vid1042_28',\n",
       "  'vid528_25',\n",
       "  'vid689_17',\n",
       "  'vid675_27',\n",
       "  'vid1075_3',\n",
       "  'vid576_9',\n",
       "  'vid17_28',\n",
       "  'vid607_8',\n",
       "  'vid27_36',\n",
       "  'vid1014_49',\n",
       "  'vid140_23',\n",
       "  'vid15_36',\n",
       "  'vid239_36',\n",
       "  'vid334_18',\n",
       "  'vid210_21',\n",
       "  'vid843_33',\n",
       "  'vid709_5',\n",
       "  'vid898_5',\n",
       "  'vid569_42',\n",
       "  'vid462_15',\n",
       "  'vid769_22',\n",
       "  'vid620_25',\n",
       "  'vid929_26',\n",
       "  'vid183_6',\n",
       "  'vid1168_29',\n",
       "  'vid738_30',\n",
       "  'vid415_29',\n",
       "  'vid932_10',\n",
       "  'vid664_4',\n",
       "  'vid340_21',\n",
       "  'vid471_11',\n",
       "  'vid983_2',\n",
       "  'vid868_9',\n",
       "  'vid808_25',\n",
       "  'vid254_51',\n",
       "  'vid943_22',\n",
       "  'vid989_26',\n",
       "  'vid1027_20',\n",
       "  'vid757_41',\n",
       "  'vid405_20',\n",
       "  'vid104_24',\n",
       "  'vid104_14',\n",
       "  'vid1182_26',\n",
       "  'vid678_37',\n",
       "  'vid254_42',\n",
       "  'vid799_34',\n",
       "  'vid674_0',\n",
       "  'vid1069_40',\n",
       "  'vid938_0',\n",
       "  'vid606_23',\n",
       "  'vid678_55',\n",
       "  'vid725_12',\n",
       "  'vid186_23',\n",
       "  'vid795_21',\n",
       "  'vid686_25',\n",
       "  'vid40_41',\n",
       "  'vid522_33',\n",
       "  'vid449_13',\n",
       "  'vid27_3',\n",
       "  'vid932_2',\n",
       "  'vid214_46',\n",
       "  'vid1131_19',\n",
       "  'vid539_7',\n",
       "  'vid128_39',\n",
       "  'vid304_10',\n",
       "  'vid198_17',\n",
       "  'vid878_49',\n",
       "  'vid734_14',\n",
       "  'vid43_24',\n",
       "  'vid912_31',\n",
       "  'vid320_11',\n",
       "  'vid898_13',\n",
       "  'vid102_18',\n",
       "  'vid582_51',\n",
       "  'vid607_36',\n",
       "  'vid34_25',\n",
       "  'vid457_13',\n",
       "  'vid811_5',\n",
       "  'vid199_7',\n",
       "  'vid103_6',\n",
       "  'vid393_1',\n",
       "  'vid705_1',\n",
       "  'vid1139_54',\n",
       "  'vid958_19',\n",
       "  'vid667_30',\n",
       "  'vid514_16',\n",
       "  'vid400_27',\n",
       "  'vid267_3',\n",
       "  'vid551_24',\n",
       "  'vid1002_3',\n",
       "  'vid581_33',\n",
       "  'vid782_25',\n",
       "  'vid431_34',\n",
       "  'vid388_18',\n",
       "  'vid503_40',\n",
       "  'vid58_39',\n",
       "  'vid1158_34',\n",
       "  'vid385_8',\n",
       "  'vid573_19',\n",
       "  'vid475_10',\n",
       "  'vid1017_21',\n",
       "  'vid724_4',\n",
       "  'vid564_25',\n",
       "  'vid780_10',\n",
       "  'vid300_18',\n",
       "  'vid76_10',\n",
       "  'vid881_18',\n",
       "  'vid289_10',\n",
       "  'vid1107_12',\n",
       "  'vid773_24',\n",
       "  'vid1159_45',\n",
       "  'vid71_18',\n",
       "  'vid1067_4',\n",
       "  'vid929_17',\n",
       "  'vid476_4',\n",
       "  'vid753_1',\n",
       "  'vid1022_10',\n",
       "  'vid90_11',\n",
       "  'vid435_45',\n",
       "  'vid958_28',\n",
       "  'vid861_26',\n",
       "  'vid961_3',\n",
       "  'vid292_24',\n",
       "  'vid28_44',\n",
       "  'vid888_4',\n",
       "  'vid35_33',\n",
       "  'vid250_26',\n",
       "  'vid120_6',\n",
       "  'vid1000_27',\n",
       "  'vid161_2',\n",
       "  'vid620_13',\n",
       "  'vid360_25',\n",
       "  'vid1044_36',\n",
       "  'vid114_23',\n",
       "  'vid913_49',\n",
       "  'vid938_52',\n",
       "  'vid1036_20',\n",
       "  'vid1125_24',\n",
       "  'vid1166_16',\n",
       "  'vid1173_0',\n",
       "  'vid840_24',\n",
       "  'vid727_15',\n",
       "  'vid899_29',\n",
       "  'vid70_16',\n",
       "  'vid1035_9',\n",
       "  'vid737_33',\n",
       "  'vid147_33',\n",
       "  'vid614_15',\n",
       "  'vid926_9',\n",
       "  'vid1188_55',\n",
       "  'vid752_53',\n",
       "  'vid832_22',\n",
       "  'vid404_0',\n",
       "  'vid798_29',\n",
       "  'vid658_1',\n",
       "  'vid1181_3',\n",
       "  'vid352_38',\n",
       "  'vid714_26',\n",
       "  'vid111_3',\n",
       "  'vid1190_21',\n",
       "  'vid123_44',\n",
       "  'vid593_24',\n",
       "  'vid1107_48',\n",
       "  'vid888_21',\n",
       "  'vid552_30',\n",
       "  'vid756_45',\n",
       "  'vid326_27',\n",
       "  'vid749_21',\n",
       "  'vid795_38',\n",
       "  'vid152_17',\n",
       "  'vid646_2',\n",
       "  'vid254_22',\n",
       "  'vid1156_14',\n",
       "  'vid1181_13',\n",
       "  'vid325_22',\n",
       "  'vid913_22',\n",
       "  'vid510_44',\n",
       "  'vid358_33',\n",
       "  'vid929_52',\n",
       "  'vid198_58',\n",
       "  'vid171_26',\n",
       "  'vid945_36',\n",
       "  'vid898_23',\n",
       "  'vid54_43',\n",
       "  'vid29_7',\n",
       "  'vid888_10',\n",
       "  'vid1179_26',\n",
       "  'vid933_6',\n",
       "  'vid359_18',\n",
       "  'vid72_4',\n",
       "  'vid802_24',\n",
       "  'vid855_15',\n",
       "  'vid769_21',\n",
       "  'vid406_15',\n",
       "  'vid1027_11',\n",
       "  'vid1175_45',\n",
       "  'vid408_18',\n",
       "  'vid256_15',\n",
       "  'vid448_3',\n",
       "  'vid763_2',\n",
       "  'vid101_19',\n",
       "  'vid887_0',\n",
       "  'vid1190_8',\n",
       "  'vid170_3',\n",
       "  'vid1094_28',\n",
       "  'vid733_41',\n",
       "  'vid806_0',\n",
       "  'vid766_13',\n",
       "  'vid817_9',\n",
       "  'vid409_8',\n",
       "  'vid333_32',\n",
       "  'vid90_1',\n",
       "  'vid917_15',\n",
       "  'vid206_21',\n",
       "  'vid13_50',\n",
       "  'vid85_27',\n",
       "  'vid902_24',\n",
       "  'vid751_8',\n",
       "  'vid857_40',\n",
       "  'vid894_37',\n",
       "  'vid447_57',\n",
       "  'vid1145_14',\n",
       "  'vid878_5',\n",
       "  'vid336_12',\n",
       "  'vid498_39',\n",
       "  'vid803_14',\n",
       "  'vid1177_24',\n",
       "  'vid132_4',\n",
       "  'vid384_27',\n",
       "  'vid76_21',\n",
       "  'vid330_49',\n",
       "  'vid598_54',\n",
       "  'vid140_5',\n",
       "  'vid411_13',\n",
       "  'vid1106_17',\n",
       "  'vid1120_52',\n",
       "  'vid193_28',\n",
       "  'vid886_30',\n",
       "  'vid196_6',\n",
       "  'vid1029_16',\n",
       "  'vid750_16',\n",
       "  'vid223_29',\n",
       "  'vid1111_36',\n",
       "  'vid689_7',\n",
       "  'vid309_1',\n",
       "  'vid641_5',\n",
       "  'vid1018_26',\n",
       "  'vid159_6',\n",
       "  'vid573_30',\n",
       "  'vid1103_46',\n",
       "  'vid520_10',\n",
       "  'vid261_34',\n",
       "  'vid274_16',\n",
       "  'vid435_6',\n",
       "  'vid322_9',\n",
       "  'vid745_31',\n",
       "  'vid905_42',\n",
       "  'vid366_7',\n",
       "  'vid383_19',\n",
       "  'vid975_14',\n",
       "  'vid18_21',\n",
       "  'vid1193_38',\n",
       "  'vid262_1',\n",
       "  'vid858_39',\n",
       "  'vid466_41',\n",
       "  'vid86_30',\n",
       "  'vid179_12',\n",
       "  'vid153_9',\n",
       "  'vid277_5',\n",
       "  'vid1062_16',\n",
       "  'vid549_11',\n",
       "  'vid1020_13',\n",
       "  'vid549_36',\n",
       "  'vid542_24',\n",
       "  'vid774_4',\n",
       "  'vid696_46',\n",
       "  'vid39_26',\n",
       "  'vid115_9',\n",
       "  'vid288_25',\n",
       "  'vid970_12',\n",
       "  'vid629_7',\n",
       "  'vid830_54',\n",
       "  'vid987_31',\n",
       "  'vid388_35',\n",
       "  'vid564_16',\n",
       "  'vid735_5',\n",
       "  'vid1193_19',\n",
       "  'vid1003_32',\n",
       "  'vid940_21',\n",
       "  'vid298_7',\n",
       "  'vid1105_16',\n",
       "  'vid652_31',\n",
       "  'vid555_11',\n",
       "  'vid798_36',\n",
       "  'vid453_25',\n",
       "  'vid641_22',\n",
       "  'vid32_17',\n",
       "  'vid83_31',\n",
       "  'vid3_29',\n",
       "  'vid789_29',\n",
       "  'vid871_1',\n",
       "  'vid867_26',\n",
       "  'vid421_18',\n",
       "  'vid339_3',\n",
       "  'vid161_4',\n",
       "  'vid954_7',\n",
       "  'vid482_28',\n",
       "  'vid1198_12',\n",
       "  'vid257_5',\n",
       "  'vid697_33',\n",
       "  'vid958_17',\n",
       "  'vid457_15',\n",
       "  'vid631_21',\n",
       "  'vid920_26',\n",
       "  'vid373_9',\n",
       "  'vid658_4',\n",
       "  'vid598_44',\n",
       "  'vid625_11',\n",
       "  'vid117_34',\n",
       "  'vid611_34',\n",
       "  'vid986_8',\n",
       "  'vid62_22',\n",
       "  'vid424_0',\n",
       "  'vid390_14',\n",
       "  'vid572_2',\n",
       "  'vid869_47',\n",
       "  'vid909_42',\n",
       "  'vid631_2',\n",
       "  'vid230_1',\n",
       "  'vid175_13',\n",
       "  'vid835_32',\n",
       "  'vid106_28',\n",
       "  'vid543_48',\n",
       "  'vid460_15',\n",
       "  'vid23_37',\n",
       "  'vid348_7',\n",
       "  'vid745_4',\n",
       "  'vid680_34',\n",
       "  'vid15_9',\n",
       "  'vid247_30',\n",
       "  'vid884_2',\n",
       "  'vid666_22',\n",
       "  'vid506_37',\n",
       "  'vid79_14',\n",
       "  'vid1123_12',\n",
       "  'vid877_2',\n",
       "  'vid250_34',\n",
       "  'vid901_7',\n",
       "  'vid1019_7',\n",
       "  'vid721_16',\n",
       "  'vid41_8',\n",
       "  'vid119_23',\n",
       "  'vid1175_7',\n",
       "  'vid1121_6',\n",
       "  'vid939_7',\n",
       "  'vid1027_24',\n",
       "  'vid1018_0',\n",
       "  'vid213_31',\n",
       "  'vid111_15',\n",
       "  'vid296_24',\n",
       "  'vid783_19',\n",
       "  'vid426_32',\n",
       "  'vid933_31',\n",
       "  'vid466_51',\n",
       "  'vid355_17',\n",
       "  'vid761_16',\n",
       "  'vid895_18',\n",
       "  'vid363_15',\n",
       "  'vid1118_2',\n",
       "  'vid478_33',\n",
       "  'vid569_23',\n",
       "  'vid1115_42',\n",
       "  'vid116_22',\n",
       "  'vid790_18',\n",
       "  'vid1052_23',\n",
       "  'vid541_36',\n",
       "  'vid779_33',\n",
       "  'vid1152_31',\n",
       "  'vid168_2',\n",
       "  'vid257_48',\n",
       "  'vid696_32',\n",
       "  'vid1050_30',\n",
       "  'vid558_10',\n",
       "  'vid23_38',\n",
       "  'vid1124_26',\n",
       "  'vid100_8',\n",
       "  'vid179_20',\n",
       "  'vid433_4',\n",
       "  'vid879_5',\n",
       "  'vid456_2',\n",
       "  'vid57_3',\n",
       "  'vid924_32',\n",
       "  'vid399_17',\n",
       "  'vid174_15',\n",
       "  'vid1081_12',\n",
       "  'vid1055_17',\n",
       "  'vid254_14',\n",
       "  'vid790_26',\n",
       "  'vid435_3',\n",
       "  'vid974_22',\n",
       "  'vid530_9',\n",
       "  'vid981_29',\n",
       "  'vid691_12',\n",
       "  'vid896_43',\n",
       "  'vid242_13',\n",
       "  'vid340_13',\n",
       "  'vid1017_10',\n",
       "  'vid729_31',\n",
       "  'vid669_37',\n",
       "  'vid173_21',\n",
       "  'vid671_1',\n",
       "  'vid704_15',\n",
       "  'vid536_1',\n",
       "  'vid561_18',\n",
       "  'vid505_1',\n",
       "  'vid574_26',\n",
       "  'vid960_14',\n",
       "  'vid584_10',\n",
       "  'vid931_6',\n",
       "  'vid449_56',\n",
       "  'vid840_18',\n",
       "  'vid494_49',\n",
       "  'vid1013_26',\n",
       "  'vid653_32',\n",
       "  'vid910_6',\n",
       "  'vid283_32',\n",
       "  'vid1183_27',\n",
       "  'vid968_35',\n",
       "  'vid644_4',\n",
       "  'vid556_30',\n",
       "  'vid969_18',\n",
       "  'vid475_7',\n",
       "  'vid27_40',\n",
       "  'vid571_2',\n",
       "  'vid1011_18',\n",
       "  'vid891_11',\n",
       "  'vid537_7',\n",
       "  'vid998_13',\n",
       "  'vid297_35',\n",
       "  'vid259_18',\n",
       "  'vid773_57',\n",
       "  'vid795_25',\n",
       "  'vid38_50',\n",
       "  'vid520_16',\n",
       "  'vid300_4',\n",
       "  'vid1153_3',\n",
       "  'vid512_5',\n",
       "  'vid833_14',\n",
       "  'vid714_18',\n",
       "  'vid848_20',\n",
       "  'vid608_57',\n",
       "  'vid294_33',\n",
       "  'vid12_42',\n",
       "  'vid1156_23',\n",
       "  'vid425_13',\n",
       "  'vid115_15',\n",
       "  'vid100_24',\n",
       "  'vid924_18',\n",
       "  'vid422_8',\n",
       "  'vid916_19',\n",
       "  'vid901_13',\n",
       "  'vid786_14',\n",
       "  'vid913_35',\n",
       "  'vid1196_32',\n",
       "  'vid386_5',\n",
       "  'vid1193_28',\n",
       "  'vid430_43',\n",
       "  'vid499_8',\n",
       "  'vid106_24',\n",
       "  'vid419_38',\n",
       "  'vid1069_13',\n",
       "  'vid503_41',\n",
       "  'vid878_29',\n",
       "  'vid1118_35',\n",
       "  'vid131_2',\n",
       "  'vid310_34',\n",
       "  'vid115_17',\n",
       "  'vid451_19',\n",
       "  'vid620_7',\n",
       "  'vid1185_40',\n",
       "  'vid502_11',\n",
       "  'vid249_23',\n",
       "  'vid1042_13',\n",
       "  'vid1007_14',\n",
       "  'vid299_7',\n",
       "  'vid1150_36',\n",
       "  'vid866_37',\n",
       "  'vid545_8',\n",
       "  'vid327_23',\n",
       "  'vid724_12',\n",
       "  'vid652_27',\n",
       "  'vid361_0',\n",
       "  'vid775_18',\n",
       "  'vid15_38',\n",
       "  'vid524_18',\n",
       "  'vid1033_19',\n",
       "  'vid944_31',\n",
       "  'vid608_0',\n",
       "  'vid611_23',\n",
       "  'vid93_25',\n",
       "  'vid281_15',\n",
       "  'vid117_12',\n",
       "  'vid535_39',\n",
       "  'vid479_0',\n",
       "  'vid769_50',\n",
       "  'vid316_15',\n",
       "  'vid1151_29',\n",
       "  'vid786_20',\n",
       "  'vid304_25',\n",
       "  'vid909_27',\n",
       "  'vid271_25',\n",
       "  'vid383_4',\n",
       "  'vid1196_36',\n",
       "  'vid584_31',\n",
       "  'vid115_0',\n",
       "  'vid1173_20',\n",
       "  'vid428_16',\n",
       "  'vid552_38',\n",
       "  'vid490_52',\n",
       "  'vid749_11',\n",
       "  'vid951_20',\n",
       "  'vid799_40',\n",
       "  'vid604_28',\n",
       "  'vid117_21',\n",
       "  'vid133_17',\n",
       "  'vid173_56',\n",
       "  'vid249_29',\n",
       "  'vid88_20',\n",
       "  'vid62_5',\n",
       "  'vid599_26',\n",
       "  'vid28_36',\n",
       "  'vid691_10',\n",
       "  'vid1160_31',\n",
       "  'vid956_25',\n",
       "  'vid748_24',\n",
       "  'vid932_12',\n",
       "  'vid1112_5',\n",
       "  'vid1102_49',\n",
       "  'vid1013_40',\n",
       "  'vid130_17',\n",
       "  'vid514_26',\n",
       "  'vid1071_8',\n",
       "  'vid585_14',\n",
       "  'vid123_27',\n",
       "  'vid921_40',\n",
       "  'vid1097_3',\n",
       "  'vid31_4',\n",
       "  'vid1099_5',\n",
       "  'vid190_5',\n",
       "  'vid670_1',\n",
       "  'vid334_9',\n",
       "  'vid11_27',\n",
       "  'vid789_23',\n",
       "  'vid794_34',\n",
       "  'vid901_36',\n",
       "  'vid468_0',\n",
       "  'vid613_7',\n",
       "  'vid740_5',\n",
       "  'vid461_24',\n",
       "  'vid1104_9',\n",
       "  'vid900_20',\n",
       "  'vid947_20',\n",
       "  'vid1014_38',\n",
       "  'vid272_3',\n",
       "  'vid322_7',\n",
       "  'vid49_20',\n",
       "  'vid551_46',\n",
       "  'vid1069_27',\n",
       "  'vid532_26',\n",
       "  'vid130_8',\n",
       "  'vid617_37',\n",
       "  'vid1113_0',\n",
       "  'vid891_25',\n",
       "  'vid57_13',\n",
       "  'vid1140_17',\n",
       "  'vid636_17',\n",
       "  'vid863_12',\n",
       "  'vid934_18',\n",
       "  'vid135_22',\n",
       "  'vid25_16',\n",
       "  'vid1098_28',\n",
       "  'vid614_34',\n",
       "  'vid302_21',\n",
       "  'vid660_19',\n",
       "  'vid1136_24',\n",
       "  'vid1137_14',\n",
       "  'vid139_48',\n",
       "  'vid945_40',\n",
       "  'vid451_41',\n",
       "  'vid1168_8',\n",
       "  'vid1061_12',\n",
       "  'vid130_26',\n",
       "  'vid952_9',\n",
       "  'vid1180_38',\n",
       "  'vid695_51',\n",
       "  'vid430_30',\n",
       "  'vid605_11',\n",
       "  'vid1144_10',\n",
       "  'vid866_46',\n",
       "  'vid265_6',\n",
       "  'vid1116_43',\n",
       "  'vid768_26',\n",
       "  'vid55_3',\n",
       "  'vid324_35',\n",
       "  'vid1055_14',\n",
       "  'vid451_37',\n",
       "  'vid882_19',\n",
       "  'vid482_27',\n",
       "  'vid1002_16',\n",
       "  'vid1071_1',\n",
       "  'vid427_6',\n",
       "  'vid138_5',\n",
       "  'vid865_23',\n",
       "  'vid196_0',\n",
       "  'vid1149_16',\n",
       "  'vid1154_0',\n",
       "  'vid148_7',\n",
       "  'vid134_11',\n",
       "  'vid253_1',\n",
       "  'vid392_17',\n",
       "  'vid158_6',\n",
       "  'vid434_13',\n",
       "  'vid631_16',\n",
       "  'vid228_10',\n",
       "  'vid1172_50',\n",
       "  'vid336_33',\n",
       "  'vid306_9',\n",
       "  'vid318_13',\n",
       "  'vid148_13',\n",
       "  'vid12_39',\n",
       "  'vid893_0',\n",
       "  'vid810_31',\n",
       "  'vid615_2',\n",
       "  'vid431_6',\n",
       "  'vid268_31',\n",
       "  'vid1009_29',\n",
       "  'vid818_29',\n",
       "  'vid969_10',\n",
       "  'vid1162_25',\n",
       "  'vid392_0',\n",
       "  'vid1185_11',\n",
       "  'vid171_25',\n",
       "  'vid1142_3',\n",
       "  'vid732_9',\n",
       "  'vid846_29',\n",
       "  'vid1132_25',\n",
       "  'vid1085_15',\n",
       "  'vid225_7',\n",
       "  'vid1043_48',\n",
       "  'vid821_33',\n",
       "  'vid772_23',\n",
       "  'vid1155_14',\n",
       "  'vid1006_18',\n",
       "  'vid932_22',\n",
       "  'vid1192_33',\n",
       "  'vid84_2',\n",
       "  'vid1096_25',\n",
       "  'vid973_32',\n",
       "  'vid520_6',\n",
       "  'vid563_27',\n",
       "  'vid691_4',\n",
       "  'vid974_42',\n",
       "  'vid770_18',\n",
       "  'vid147_22',\n",
       "  'vid1019_24',\n",
       "  'vid876_35',\n",
       "  'vid99_25',\n",
       "  'vid514_23',\n",
       "  'vid177_24',\n",
       "  'vid875_20',\n",
       "  'vid1050_8',\n",
       "  'vid1030_31',\n",
       "  'vid822_20',\n",
       "  'vid2_14',\n",
       "  'vid67_12',\n",
       "  'vid337_31',\n",
       "  'vid1088_23',\n",
       "  'vid837_20',\n",
       "  'vid842_32',\n",
       "  'vid391_28',\n",
       "  'vid1074_38',\n",
       "  'vid283_16',\n",
       "  'vid1194_15',\n",
       "  'vid1177_45',\n",
       "  'vid905_30',\n",
       "  'vid1079_36',\n",
       "  'vid1084_29',\n",
       "  'vid483_17',\n",
       "  'vid992_21',\n",
       "  'vid1139_27',\n",
       "  'vid728_62',\n",
       "  'vid813_7',\n",
       "  'vid181_25',\n",
       "  'vid1020_11',\n",
       "  'vid863_11',\n",
       "  'vid968_18',\n",
       "  'vid638_10',\n",
       "  'vid618_2',\n",
       "  'vid751_31',\n",
       "  'vid674_17',\n",
       "  'vid137_32',\n",
       "  'vid744_1',\n",
       "  'vid377_24',\n",
       "  'vid819_7',\n",
       "  'vid681_23',\n",
       "  'vid342_8',\n",
       "  'vid1167_51',\n",
       "  'vid1129_30',\n",
       "  'vid872_15',\n",
       "  'vid900_18',\n",
       "  'vid894_21',\n",
       "  'vid54_5',\n",
       "  'vid116_30',\n",
       "  'vid181_21',\n",
       "  'vid468_6',\n",
       "  'vid458_25',\n",
       "  'vid1049_2',\n",
       "  'vid95_5',\n",
       "  'vid189_1',\n",
       "  'vid6_10',\n",
       "  'vid502_19',\n",
       "  'vid654_2',\n",
       "  'vid124_37',\n",
       "  'vid96_7',\n",
       "  'vid410_9',\n",
       "  'vid439_31',\n",
       "  'vid889_8',\n",
       "  'vid723_2',\n",
       "  'vid270_22',\n",
       "  'vid705_51',\n",
       "  'vid1164_30',\n",
       "  'vid1159_50',\n",
       "  'vid861_48',\n",
       "  'vid760_11',\n",
       "  'vid1033_12',\n",
       "  'vid643_5',\n",
       "  'vid721_38',\n",
       "  'vid153_20',\n",
       "  'vid541_15',\n",
       "  'vid782_34',\n",
       "  'vid728_56',\n",
       "  'vid137_10',\n",
       "  'vid726_39',\n",
       "  'vid408_27',\n",
       "  'vid970_23',\n",
       "  'vid1070_37',\n",
       "  'vid497_23',\n",
       "  'vid430_35',\n",
       "  'vid254_58',\n",
       "  'vid369_20',\n",
       "  'vid195_21',\n",
       "  'vid863_13',\n",
       "  'vid660_38',\n",
       "  'vid370_26',\n",
       "  'vid1149_39',\n",
       "  'vid317_0',\n",
       "  'vid467_14',\n",
       "  'vid94_5',\n",
       "  'vid291_10',\n",
       "  'vid436_28',\n",
       "  'vid23_34',\n",
       "  'vid830_2',\n",
       "  'vid14_21',\n",
       "  'vid632_0',\n",
       "  'vid1171_40',\n",
       "  'vid68_31',\n",
       "  'vid680_51',\n",
       "  'vid1189_27',\n",
       "  'vid1165_43',\n",
       "  'vid788_37',\n",
       "  'vid288_20',\n",
       "  'vid480_17',\n",
       "  'vid52_20',\n",
       "  'vid699_30',\n",
       "  'vid676_4',\n",
       "  'vid790_16',\n",
       "  'vid90_9',\n",
       "  'vid980_0',\n",
       "  'vid913_26',\n",
       "  'vid196_4',\n",
       "  'vid839_10',\n",
       "  'vid849_18',\n",
       "  'vid430_20',\n",
       "  'vid1170_31',\n",
       "  'vid149_39',\n",
       "  'vid1112_34',\n",
       "  'vid66_51',\n",
       "  'vid138_10',\n",
       "  'vid984_15',\n",
       "  'vid755_28',\n",
       "  'vid131_6',\n",
       "  'vid1002_25',\n",
       "  'vid734_38',\n",
       "  'vid519_38',\n",
       "  'vid324_33',\n",
       "  'vid950_15',\n",
       "  'vid1188_22',\n",
       "  'vid575_16',\n",
       "  'vid662_20',\n",
       "  'vid860_32',\n",
       "  'vid256_29',\n",
       "  'vid980_4',\n",
       "  'vid1187_12',\n",
       "  'vid343_6',\n",
       "  'vid23_42',\n",
       "  'vid788_22',\n",
       "  'vid821_34',\n",
       "  'vid376_3',\n",
       "  'vid398_33',\n",
       "  'vid1066_3',\n",
       "  'vid801_13',\n",
       "  'vid825_40',\n",
       "  'vid491_23',\n",
       "  'vid404_11',\n",
       "  'vid260_29',\n",
       "  'vid469_4',\n",
       "  'vid543_35',\n",
       "  'vid776_5',\n",
       "  'vid974_43',\n",
       "  'vid354_41',\n",
       "  'vid942_0',\n",
       "  'vid39_40',\n",
       "  'vid1083_38',\n",
       "  'vid1191_8',\n",
       "  'vid244_9',\n",
       "  'vid458_27',\n",
       "  'vid220_18',\n",
       "  'vid1112_26',\n",
       "  'vid21_25',\n",
       "  'vid1103_5',\n",
       "  'vid1132_19',\n",
       "  'vid492_21',\n",
       "  'vid1137_13',\n",
       "  'vid580_41',\n",
       "  'vid695_50',\n",
       "  'vid419_55',\n",
       "  'vid115_40',\n",
       "  'vid326_9',\n",
       "  'vid732_1',\n",
       "  'vid404_27',\n",
       "  'vid472_29',\n",
       "  'vid920_19',\n",
       "  'vid619_35',\n",
       "  'vid386_15',\n",
       "  'vid853_20',\n",
       "  'vid47_2',\n",
       "  'vid794_9',\n",
       "  'vid484_11',\n",
       "  'vid60_26',\n",
       "  'vid384_16',\n",
       "  'vid1069_7',\n",
       "  'vid443_13',\n",
       "  'vid136_33',\n",
       "  'vid767_18',\n",
       "  'vid286_29',\n",
       "  'vid437_14',\n",
       "  'vid724_13',\n",
       "  'vid632_25',\n",
       "  'vid145_24',\n",
       "  'vid834_15',\n",
       "  'vid718_19',\n",
       "  'vid1007_43',\n",
       "  'vid824_40',\n",
       "  'vid780_23',\n",
       "  'vid723_7',\n",
       "  'vid167_19',\n",
       "  'vid324_14',\n",
       "  'vid1025_31',\n",
       "  'vid336_24',\n",
       "  'vid1035_35',\n",
       "  'vid374_28',\n",
       "  'vid298_26',\n",
       "  'vid777_38',\n",
       "  'vid203_20',\n",
       "  'vid536_6',\n",
       "  'vid1065_18',\n",
       "  'vid1089_40',\n",
       "  'vid1200_4',\n",
       "  'vid1098_38',\n",
       "  'vid424_43',\n",
       "  'vid507_18',\n",
       "  'vid57_11',\n",
       "  'vid951_26',\n",
       "  'vid1079_18',\n",
       "  'vid736_20',\n",
       "  'vid1157_27',\n",
       "  'vid553_8',\n",
       "  'vid184_4',\n",
       "  'vid829_14',\n",
       "  'vid249_9',\n",
       "  'vid1176_19',\n",
       "  'vid27_15',\n",
       "  'vid960_26',\n",
       "  'vid1154_39',\n",
       "  'vid377_0',\n",
       "  'vid694_16',\n",
       "  'vid1075_30',\n",
       "  'vid60_30',\n",
       "  'vid799_30',\n",
       "  'vid970_11',\n",
       "  'vid1183_11',\n",
       "  'vid721_5',\n",
       "  'vid197_47',\n",
       "  'vid941_0',\n",
       "  'vid790_38',\n",
       "  'vid536_26',\n",
       "  'vid843_18',\n",
       "  'vid189_10',\n",
       "  'vid726_12',\n",
       "  'vid1198_3',\n",
       "  'vid835_1',\n",
       "  'vid303_32',\n",
       "  'vid97_9',\n",
       "  'vid569_17',\n",
       "  'vid230_33',\n",
       "  'vid530_15',\n",
       "  'vid309_49',\n",
       "  'vid1121_21',\n",
       "  'vid133_5',\n",
       "  'vid683_6',\n",
       "  'vid850_34',\n",
       "  'vid927_34',\n",
       "  'vid611_19',\n",
       "  'vid1040_54',\n",
       "  'vid960_3',\n",
       "  'vid400_22',\n",
       "  'vid439_8',\n",
       "  'vid994_0',\n",
       "  'vid984_17',\n",
       "  'vid903_0',\n",
       "  'vid999_16',\n",
       "  'vid1136_26',\n",
       "  'vid1112_33',\n",
       "  'vid707_52',\n",
       "  'vid716_32',\n",
       "  'vid468_21',\n",
       "  'vid454_12',\n",
       "  'vid13_27',\n",
       "  'vid133_19',\n",
       "  'vid1100_54',\n",
       "  'vid194_25',\n",
       "  'vid457_12',\n",
       "  'vid728_28',\n",
       "  'vid621_15',\n",
       "  'vid1086_38',\n",
       "  'vid786_25',\n",
       "  'vid1107_25',\n",
       "  'vid503_12',\n",
       "  'vid413_14',\n",
       "  'vid64_36',\n",
       "  'vid411_19',\n",
       "  'vid467_17',\n",
       "  'vid88_21',\n",
       "  'vid66_20',\n",
       "  'vid143_46',\n",
       "  'vid6_21',\n",
       "  'vid1082_23',\n",
       "  'vid845_18',\n",
       "  'vid199_47',\n",
       "  'vid82_27',\n",
       "  'vid1036_17',\n",
       "  'vid439_6',\n",
       "  'vid429_3',\n",
       "  'vid147_18',\n",
       "  'vid716_35',\n",
       "  'vid387_34',\n",
       "  'vid148_16',\n",
       "  'vid127_23',\n",
       "  'vid211_0',\n",
       "  'vid249_7',\n",
       "  'vid585_34',\n",
       "  'vid252_33',\n",
       "  'vid691_14',\n",
       "  'vid565_27',\n",
       "  'vid1172_59',\n",
       "  'vid857_28',\n",
       "  'vid1169_54',\n",
       "  'vid1175_9',\n",
       "  'vid1103_17',\n",
       "  'vid1172_42',\n",
       "  'vid961_18',\n",
       "  'vid732_27',\n",
       "  'vid833_8',\n",
       "  'vid127_18',\n",
       "  'vid577_29',\n",
       "  'vid842_7',\n",
       "  ...]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(pickle_file):\n",
    "    try:\n",
    "        with open(pickle_file, 'rb') as f:\n",
    "            pickle_data = pickle.load(f)\n",
    "    except UnicodeDecodeError as e:\n",
    "        with open(pickle_file, 'rb') as f:\n",
    "            pickle_data = pickle.load(f, encoding='latin1')\n",
    "    except Exception as e:\n",
    "        print('Unable to load data ', pickle_file, ':', e)\n",
    "        raise\n",
    "    return pickle_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "objects = load_pickle(\"youtube2text_iccv15/worddict.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_idict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for kk, vv in objects.items():\n",
    "    word_idict[vv] = kk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 'a',\n",
       " 3: 'is',\n",
       " 4: 'the',\n",
       " 5: 'man',\n",
       " 6: 'woman',\n",
       " 7: 'on',\n",
       " 8: 'in',\n",
       " 9: 'playing',\n",
       " 10: 'are',\n",
       " 11: 'of',\n",
       " 12: 'and',\n",
       " 13: 'with',\n",
       " 14: 'person',\n",
       " 15: 'to',\n",
       " 16: 'into',\n",
       " 17: 'an',\n",
       " 18: 'two',\n",
       " 19: 'dog',\n",
       " 20: 'cat',\n",
       " 21: 'girl',\n",
       " 22: 'his',\n",
       " 23: 'boy',\n",
       " 24: 'cutting',\n",
       " 25: 'someone',\n",
       " 26: 'some',\n",
       " 27: 'riding',\n",
       " 28: 'dancing',\n",
       " 29: 'baby',\n",
       " 30: 'water',\n",
       " 31: 'guitar',\n",
       " 32: 'slicing',\n",
       " 33: 'men',\n",
       " 34: 'from',\n",
       " 35: 'lady',\n",
       " 36: 'walking',\n",
       " 37: 'eating',\n",
       " 38: 'up',\n",
       " 39: 'down',\n",
       " 40: 'horse',\n",
       " 41: 'her',\n",
       " 42: 'car',\n",
       " 43: 'cooking',\n",
       " 44: 'doing',\n",
       " 45: 'running',\n",
       " 46: 'at',\n",
       " 47: 'women',\n",
       " 48: 'people',\n",
       " 49: 'something',\n",
       " 50: 'bowl',\n",
       " 51: 'food',\n",
       " 52: 'making',\n",
       " 53: 'talking',\n",
       " 54: 'out',\n",
       " 55: 'ball',\n",
       " 56: 'small',\n",
       " 57: 'off',\n",
       " 58: \"'s\",\n",
       " 59: 'singing',\n",
       " 60: 'it',\n",
       " 61: 'meat',\n",
       " 62: 'onion',\n",
       " 63: 'pan',\n",
       " 64: 'knife',\n",
       " 65: 'by',\n",
       " 66: 'potato',\n",
       " 67: 'one',\n",
       " 68: 'being',\n",
       " 69: 'over',\n",
       " 70: 'young',\n",
       " 71: 'little',\n",
       " 72: 'piano',\n",
       " 73: 'putting',\n",
       " 74: 'plays',\n",
       " 75: 'through',\n",
       " 76: 'how',\n",
       " 77: 'for',\n",
       " 78: 'bike',\n",
       " 79: 'its',\n",
       " 80: 'paper',\n",
       " 81: 'other',\n",
       " 82: 'peeling',\n",
       " 83: 'around',\n",
       " 84: 'pouring',\n",
       " 85: 'stage',\n",
       " 86: 'monkey',\n",
       " 87: 'sitting',\n",
       " 88: 'chicken',\n",
       " 89: 'chopping',\n",
       " 90: 'chef',\n",
       " 91: 'while',\n",
       " 92: 'make',\n",
       " 93: 'road',\n",
       " 94: 'piece',\n",
       " 95: 'fish',\n",
       " 96: 'preparing',\n",
       " 97: 'bread',\n",
       " 98: 'pieces',\n",
       " 99: 'girls',\n",
       " 100: 'jumping',\n",
       " 101: 'very',\n",
       " 102: 'another',\n",
       " 103: 'trying',\n",
       " 104: 'shooting',\n",
       " 105: 'eggs',\n",
       " 106: 'slices',\n",
       " 107: 'flute',\n",
       " 108: 'cuts',\n",
       " 109: 'group',\n",
       " 110: 'animal',\n",
       " 111: 'pot',\n",
       " 112: 'guy',\n",
       " 113: 'motorcycle',\n",
       " 114: 'using',\n",
       " 115: 'fighting',\n",
       " 116: 'cut',\n",
       " 117: 'phone',\n",
       " 118: 'puppy',\n",
       " 119: 'taking',\n",
       " 120: 'three',\n",
       " 121: 'floor',\n",
       " 122: 'gun',\n",
       " 123: 'each',\n",
       " 124: 'showing',\n",
       " 125: 'rice',\n",
       " 126: 'driving',\n",
       " 127: 'egg',\n",
       " 128: 'kitten',\n",
       " 129: 'mixing',\n",
       " 130: 'performing',\n",
       " 131: 'back',\n",
       " 132: 'box',\n",
       " 133: 'holding',\n",
       " 134: 'video',\n",
       " 135: 'ground',\n",
       " 136: 'boys',\n",
       " 137: 'hand',\n",
       " 138: 'panda',\n",
       " 139: 'pool',\n",
       " 140: 'child',\n",
       " 141: 'white',\n",
       " 142: 'shrimp',\n",
       " 143: 'soccer',\n",
       " 144: 'drinking',\n",
       " 145: 'swimming',\n",
       " 146: 'standing',\n",
       " 147: 'hair',\n",
       " 148: 'moving',\n",
       " 149: 'large',\n",
       " 150: 'carrot',\n",
       " 151: 'grass',\n",
       " 152: 'he',\n",
       " 153: 'song',\n",
       " 154: 'puts',\n",
       " 155: 'dough',\n",
       " 156: 'their',\n",
       " 157: 'vegetables',\n",
       " 158: 'toy',\n",
       " 159: 'garlic',\n",
       " 160: 'bicycle',\n",
       " 161: 'cook',\n",
       " 162: 'dance',\n",
       " 163: 'street',\n",
       " 164: 'dish',\n",
       " 165: 'head',\n",
       " 166: 'field',\n",
       " 167: 'kid',\n",
       " 168: 'hands',\n",
       " 169: 'music',\n",
       " 170: 'cleaning',\n",
       " 171: 'jumps',\n",
       " 172: 'sauce',\n",
       " 173: 'across',\n",
       " 174: 'beach',\n",
       " 175: 'dogs',\n",
       " 176: 'frying',\n",
       " 177: 'sliced',\n",
       " 178: 'oil',\n",
       " 179: 'elephant',\n",
       " 180: 'bed',\n",
       " 181: 'as',\n",
       " 182: 'butter',\n",
       " 183: 'keyboard',\n",
       " 184: 'face',\n",
       " 185: 'rides',\n",
       " 186: 'played',\n",
       " 187: 'looking',\n",
       " 188: 'pizza',\n",
       " 189: 'tomato',\n",
       " 190: 'onions',\n",
       " 191: 'adding',\n",
       " 192: 'table',\n",
       " 193: 'about',\n",
       " 194: 'vegetable',\n",
       " 195: 'falls',\n",
       " 196: 'wall',\n",
       " 197: 'runs',\n",
       " 198: 'front',\n",
       " 199: 'then',\n",
       " 200: 'kichen',\n",
       " 201: 'together',\n",
       " 202: 'kids',\n",
       " 203: 'tree',\n",
       " 204: 'rope',\n",
       " 205: 'player',\n",
       " 206: 'bear',\n",
       " 207: 'green',\n",
       " 208: 'children',\n",
       " 209: 'potatoes',\n",
       " 210: 'board',\n",
       " 211: 'play',\n",
       " 212: 'pours',\n",
       " 213: 'funny',\n",
       " 214: 'climbing',\n",
       " 215: 'going',\n",
       " 216: 'stirring',\n",
       " 217: 'basketball',\n",
       " 218: 'milk',\n",
       " 219: 'watching',\n",
       " 220: 'finger',\n",
       " 221: 'room',\n",
       " 222: 'ingredients',\n",
       " 223: 'camera',\n",
       " 224: 'falling',\n",
       " 225: 'onto',\n",
       " 226: 'plane',\n",
       " 227: 'pushing',\n",
       " 228: 'put',\n",
       " 229: 'football',\n",
       " 230: 'walks',\n",
       " 231: 'violin',\n",
       " 232: 'flying',\n",
       " 233: 'flour',\n",
       " 234: 'tiger',\n",
       " 235: 'was',\n",
       " 236: 'top',\n",
       " 237: 'cucumber',\n",
       " 238: 'band',\n",
       " 239: 'this',\n",
       " 240: 'kissing',\n",
       " 241: 'makeup',\n",
       " 242: 'game',\n",
       " 243: 'getting',\n",
       " 244: 'couple',\n",
       " 245: 'lifting',\n",
       " 246: 'exercise',\n",
       " 247: 'several',\n",
       " 248: 'licking',\n",
       " 249: 'she',\n",
       " 250: 'bird',\n",
       " 251: 'carrots',\n",
       " 252: 'applying',\n",
       " 253: 'chair',\n",
       " 254: 'cheese',\n",
       " 255: 'banana',\n",
       " 256: 'boat',\n",
       " 257: 'half',\n",
       " 258: 'seasoning',\n",
       " 259: 'speaking',\n",
       " 260: 'glass',\n",
       " 261: 'tail',\n",
       " 262: 'black',\n",
       " 263: 'rabbit',\n",
       " 264: 'plastic',\n",
       " 265: 'laughing',\n",
       " 266: 'lion',\n",
       " 267: 'liquid',\n",
       " 268: 'outside',\n",
       " 269: 'ice',\n",
       " 270: 'can',\n",
       " 271: 'them',\n",
       " 272: 'machine',\n",
       " 273: 'along',\n",
       " 274: 'bag',\n",
       " 275: 'cake',\n",
       " 276: 'behind',\n",
       " 277: 'house',\n",
       " 278: 'train',\n",
       " 279: 'side',\n",
       " 280: 'plate',\n",
       " 281: 'giving',\n",
       " 282: 'get',\n",
       " 283: 'cup',\n",
       " 284: 'tricks',\n",
       " 285: 'movie',\n",
       " 286: 'shot',\n",
       " 287: 'poured',\n",
       " 288: 'snow',\n",
       " 289: 'air',\n",
       " 290: 'open',\n",
       " 291: 'red',\n",
       " 292: 'mirror',\n",
       " 293: 'show',\n",
       " 294: 'wood',\n",
       " 295: 'mouth',\n",
       " 296: 'stairs',\n",
       " 297: 'raw',\n",
       " 298: 'that',\n",
       " 299: 'old',\n",
       " 300: 'leaves',\n",
       " 301: 'him',\n",
       " 302: 'cute',\n",
       " 303: 'lying',\n",
       " 304: 'opening',\n",
       " 305: 'like',\n",
       " 306: 'exercising',\n",
       " 307: 'container',\n",
       " 308: 'reading',\n",
       " 309: 'they',\n",
       " 310: 'inside',\n",
       " 311: 'race',\n",
       " 312: 'washing',\n",
       " 313: 'instrument',\n",
       " 314: 'pepper',\n",
       " 315: 'frog',\n",
       " 316: 'wooden',\n",
       " 317: 'apple',\n",
       " 318: 'rolling',\n",
       " 319: 'drums',\n",
       " 320: 'firing',\n",
       " 321: 'ride',\n",
       " 322: 'does',\n",
       " 323: 'kicking',\n",
       " 324: 'carrying',\n",
       " 325: 'broccoli',\n",
       " 326: 'drawing',\n",
       " 327: 'stick',\n",
       " 328: 'polar',\n",
       " 329: 'under',\n",
       " 330: 'pork',\n",
       " 331: 'dicing',\n",
       " 332: 'kitchen',\n",
       " 333: 'animals',\n",
       " 334: 'deer',\n",
       " 335: 'bath',\n",
       " 336: 'gets',\n",
       " 337: 'pasta',\n",
       " 338: 'breaking',\n",
       " 339: 'skin',\n",
       " 340: 'chopped',\n",
       " 341: 'makes',\n",
       " 342: 'there',\n",
       " 343: 'chops',\n",
       " 344: 'boiling',\n",
       " 345: 'basket',\n",
       " 346: 'elephants',\n",
       " 347: 'sword',\n",
       " 348: 'cooked',\n",
       " 349: 'removing',\n",
       " 350: 'bottle',\n",
       " 351: 'fell',\n",
       " 352: 'watermelon',\n",
       " 353: 'sort',\n",
       " 354: 'eye',\n",
       " 355: 'skateboard',\n",
       " 356: 'hit',\n",
       " 357: 'were',\n",
       " 358: 'jump',\n",
       " 359: 'skillet',\n",
       " 360: 'forest',\n",
       " 361: 'track',\n",
       " 362: 'toddler',\n",
       " 363: 'big',\n",
       " 364: 'skating',\n",
       " 365: 'pulling',\n",
       " 366: 'slice',\n",
       " 367: 'barking',\n",
       " 368: 'mixture',\n",
       " 369: 'itself',\n",
       " 370: 'clip',\n",
       " 371: 'pineapple',\n",
       " 372: 'eats',\n",
       " 373: 'beef',\n",
       " 374: 'fat',\n",
       " 375: 'rock',\n",
       " 376: 'microphone',\n",
       " 377: 'kangaroo',\n",
       " 378: 'target',\n",
       " 379: 'laying',\n",
       " 380: 'shoots',\n",
       " 381: 'stunts',\n",
       " 382: 'hitting',\n",
       " 383: 'sliding',\n",
       " 384: 'turtle',\n",
       " 385: 'racing',\n",
       " 386: 'puppies',\n",
       " 387: 'wearing',\n",
       " 388: 'placing',\n",
       " 389: 'peeled',\n",
       " 390: 'chasing',\n",
       " 391: 'throwing',\n",
       " 392: 'noodles',\n",
       " 393: 'couch',\n",
       " 394: 'dirt',\n",
       " 395: 'himself',\n",
       " 396: 'jumped',\n",
       " 397: 'added',\n",
       " 398: 'cricket',\n",
       " 399: 'lemon',\n",
       " 400: 'takes',\n",
       " 401: 'hamster',\n",
       " 402: 'juice',\n",
       " 403: 'goal',\n",
       " 404: 'peels',\n",
       " 405: 'batter',\n",
       " 406: 'has',\n",
       " 407: 'sand',\n",
       " 408: 'stunt',\n",
       " 409: 'all',\n",
       " 410: 'boxing',\n",
       " 411: 'fire',\n",
       " 412: 'door',\n",
       " 413: 'enjoying',\n",
       " 414: 'cartoon',\n",
       " 415: 'chili',\n",
       " 416: 'slow',\n",
       " 417: 'scooter',\n",
       " 418: 'window',\n",
       " 419: 'trumpet',\n",
       " 420: 'recipe',\n",
       " 421: 'sofa',\n",
       " 422: 'fruit',\n",
       " 423: 'away',\n",
       " 424: 'loris',\n",
       " 425: 'after',\n",
       " 426: 'writing',\n",
       " 427: 'cats',\n",
       " 428: 'cage',\n",
       " 429: 'i',\n",
       " 430: 'horses',\n",
       " 431: 'indian',\n",
       " 432: 'fence',\n",
       " 433: 'zebras',\n",
       " 434: 'garden',\n",
       " 435: 'rain',\n",
       " 436: 'guys',\n",
       " 437: 'made',\n",
       " 438: 'sink',\n",
       " 439: 'pencil',\n",
       " 440: 'kind',\n",
       " 441: 'be',\n",
       " 442: 'bubble',\n",
       " 443: 'biting',\n",
       " 444: 'catch',\n",
       " 445: 'cycle',\n",
       " 446: 'short',\n",
       " 447: 'mango',\n",
       " 448: 'persons',\n",
       " 449: 'airplane',\n",
       " 450: 'store',\n",
       " 451: 'woods',\n",
       " 452: 'danced',\n",
       " 453: 'walk',\n",
       " 454: 'four',\n",
       " 455: 'weights',\n",
       " 456: 'oven',\n",
       " 457: 'sleeping',\n",
       " 458: 'feeding',\n",
       " 459: 'crying',\n",
       " 460: 'which',\n",
       " 461: 'japanese',\n",
       " 462: 'diving',\n",
       " 463: 'building',\n",
       " 464: 'legs',\n",
       " 465: 'tomatoes',\n",
       " 466: 'soup',\n",
       " 467: 'card',\n",
       " 468: 'rode',\n",
       " 469: 'seated',\n",
       " 470: 'spreading',\n",
       " 471: 'when',\n",
       " 472: 'tv',\n",
       " 473: 'slide',\n",
       " 474: 'crawling',\n",
       " 475: 'river',\n",
       " 476: 'dances',\n",
       " 477: 'truck',\n",
       " 478: 'eat',\n",
       " 479: 'somebody',\n",
       " 480: 'near',\n",
       " 481: 'baseball',\n",
       " 482: 'teaching',\n",
       " 483: 'shows',\n",
       " 484: 'hedgehog',\n",
       " 485: 'sea',\n",
       " 486: 'do',\n",
       " 487: 'snake',\n",
       " 488: 'having',\n",
       " 489: 'feet',\n",
       " 490: 'ocean',\n",
       " 491: 'high',\n",
       " 492: 'electric',\n",
       " 493: 'cream',\n",
       " 494: 'good',\n",
       " 495: 'working',\n",
       " 496: 'telephone',\n",
       " 497: 'body',\n",
       " 498: 'players',\n",
       " 499: 'hits',\n",
       " 500: 'beating',\n",
       " 501: 'scene',\n",
       " 502: 'news',\n",
       " 503: 'fight',\n",
       " 504: 'hot',\n",
       " 505: 'mushrooms',\n",
       " 506: 'ran',\n",
       " 507: 'sky',\n",
       " 508: 'rider',\n",
       " 509: 'computer',\n",
       " 510: 'picture',\n",
       " 511: 'coking',\n",
       " 512: 'jet',\n",
       " 513: 'blowing',\n",
       " 514: 'smoking',\n",
       " 515: 'hill',\n",
       " 516: 'long',\n",
       " 517: 'hanging',\n",
       " 518: 'towards',\n",
       " 519: 'scissors',\n",
       " 520: 'bus',\n",
       " 521: 'cow',\n",
       " 522: 'spices',\n",
       " 523: 'super',\n",
       " 524: 'or',\n",
       " 525: 'squirrel',\n",
       " 526: 'talks',\n",
       " 527: 'trick',\n",
       " 528: 'typing',\n",
       " 529: 'opens',\n",
       " 530: 'spaghetti',\n",
       " 531: 'did',\n",
       " 532: 'salad',\n",
       " 533: 'spoon',\n",
       " 534: 'rat',\n",
       " 535: 'practicing',\n",
       " 536: 'paws',\n",
       " 537: 'curry',\n",
       " 538: 'wheel',\n",
       " 539: 'balls',\n",
       " 540: 'helicopter',\n",
       " 541: 'prepare',\n",
       " 542: 'cracking',\n",
       " 543: 'ladies',\n",
       " 544: 'coming',\n",
       " 545: 'drinks',\n",
       " 546: 'bathing',\n",
       " 547: 'folding',\n",
       " 548: 'brushing',\n",
       " 549: 'petting',\n",
       " 550: 'strips',\n",
       " 551: 'karate',\n",
       " 552: 'yard',\n",
       " 553: 'acoustic',\n",
       " 554: 'sidewalk',\n",
       " 555: 'drink',\n",
       " 556: 'potatoe',\n",
       " 557: 'climbs',\n",
       " 558: 'tub',\n",
       " 559: 'pet',\n",
       " 560: 'bridge',\n",
       " 561: 'sugar',\n",
       " 562: 'who',\n",
       " 563: 'wrestling',\n",
       " 564: 'guns',\n",
       " 565: 'shark',\n",
       " 566: 'picking',\n",
       " 567: 'fast',\n",
       " 568: 'tries',\n",
       " 569: 'landing',\n",
       " 570: 'rifle',\n",
       " 571: 'french',\n",
       " 572: 'blender',\n",
       " 573: 'boiled',\n",
       " 574: 'line',\n",
       " 575: 'salt',\n",
       " 576: 'pole',\n",
       " 577: 'blue',\n",
       " 578: 'placed',\n",
       " 579: 'many',\n",
       " 580: 'foot',\n",
       " 581: 'tofu',\n",
       " 582: 'run',\n",
       " 583: 'motor',\n",
       " 584: 'crashes',\n",
       " 585: 'mouse',\n",
       " 586: 'looks',\n",
       " 587: 'tennis',\n",
       " 588: 'swinging',\n",
       " 589: 'adds',\n",
       " 590: 'dead',\n",
       " 591: 'pandas',\n",
       " 592: 'towel',\n",
       " 593: 'sings',\n",
       " 594: 'cards',\n",
       " 595: 'ceiling',\n",
       " 596: 'police',\n",
       " 597: 'scratching',\n",
       " 598: 'coffee',\n",
       " 599: 'huge',\n",
       " 600: 'brush',\n",
       " 601: 'shopping',\n",
       " 602: 'chop',\n",
       " 603: 'lot',\n",
       " 604: 'ate',\n",
       " 605: 'mother',\n",
       " 606: 'loaf',\n",
       " 607: 'sprinkling',\n",
       " 608: 'badger',\n",
       " 609: 'filling',\n",
       " 610: 'sheet',\n",
       " 611: 'slowly',\n",
       " 612: 'way',\n",
       " 613: 'roof',\n",
       " 614: 'places',\n",
       " 615: 'against',\n",
       " 616: 'fox',\n",
       " 617: 'noodle',\n",
       " 618: 'full',\n",
       " 619: 'trampoline',\n",
       " 620: 'pushes',\n",
       " 621: 'walked',\n",
       " 622: 'chocolate',\n",
       " 623: 'exercises',\n",
       " 624: 'mixes',\n",
       " 625: 'cliff',\n",
       " 626: 'lifts',\n",
       " 627: 'stove',\n",
       " 628: 'smiling',\n",
       " 629: 'picks',\n",
       " 630: 'bacon',\n",
       " 631: 'seeds',\n",
       " 632: 'chewing',\n",
       " 633: 'flight',\n",
       " 634: 'backwards',\n",
       " 635: 'chinese',\n",
       " 636: 'brown',\n",
       " 637: 'orange',\n",
       " 638: 'demonstrating',\n",
       " 639: 'moves',\n",
       " 640: 'television',\n",
       " 641: 'lemur',\n",
       " 642: 'laptop',\n",
       " 643: 'area',\n",
       " 644: 'catching',\n",
       " 645: 'trunk',\n",
       " 646: 'nice',\n",
       " 647: 'cigarette',\n",
       " 648: 'lake',\n",
       " 649: 'arm',\n",
       " 650: 'martial',\n",
       " 651: 'drives',\n",
       " 652: 'attacking',\n",
       " 653: 'bench',\n",
       " 654: 'thin',\n",
       " 655: 'sign',\n",
       " 656: 'clothes',\n",
       " 657: 'circles',\n",
       " 658: 'targets',\n",
       " 659: 'park',\n",
       " 660: 'fried',\n",
       " 661: 'took',\n",
       " 662: 'nose',\n",
       " 663: 'match',\n",
       " 664: 'film',\n",
       " 665: 'animated',\n",
       " 666: 'yellow',\n",
       " 667: 'path',\n",
       " 668: 'hugging',\n",
       " 669: 'ready',\n",
       " 670: 'steps',\n",
       " 671: 'microwave',\n",
       " 672: 'home',\n",
       " 673: 'hammer',\n",
       " 674: 'seeing',\n",
       " 675: 'actor',\n",
       " 676: 'cars',\n",
       " 677: 'stirs',\n",
       " 678: 'cell',\n",
       " 679: 'puppet',\n",
       " 680: 'gorilla',\n",
       " 681: 'kick',\n",
       " 682: 'paw',\n",
       " 683: 'sing',\n",
       " 684: 'kicks',\n",
       " 685: 'mountain',\n",
       " 686: 'tortilla',\n",
       " 687: 'edge',\n",
       " 688: 'package',\n",
       " 689: 'pudding',\n",
       " 690: 'sits',\n",
       " 691: 'cabbage',\n",
       " 692: 'pulls',\n",
       " 693: 'pitcher',\n",
       " 694: 'spinning',\n",
       " 695: 'containing',\n",
       " 696: 'dressed',\n",
       " 697: 'bunny',\n",
       " 698: 'crowd',\n",
       " 699: 'leaf',\n",
       " 700: 'counter',\n",
       " 701: 'teacher',\n",
       " 702: 'end',\n",
       " 703: 'female',\n",
       " 704: 'dolphin',\n",
       " 705: 'grill',\n",
       " 706: 'mans',\n",
       " 707: 'hole',\n",
       " 708: 'lawn',\n",
       " 709: 'breaks',\n",
       " 710: 'leg',\n",
       " 711: 'pistol',\n",
       " 712: 'mixed',\n",
       " 713: 'parrot',\n",
       " 714: 'ring',\n",
       " 715: 'tortoise',\n",
       " 716: 'eggplant',\n",
       " 717: 'fries',\n",
       " 718: 'holds',\n",
       " 719: 'slides',\n",
       " 720: 'cart',\n",
       " 721: 'arts',\n",
       " 722: 'grating',\n",
       " 723: 'bears',\n",
       " 724: 'fly',\n",
       " 725: 'peoples',\n",
       " 726: 'rubbing',\n",
       " 727: 'so',\n",
       " 728: 'fingers',\n",
       " 729: 'five',\n",
       " 730: 'kneading',\n",
       " 731: 'different',\n",
       " 732: 'motion',\n",
       " 733: 'toys',\n",
       " 734: 'treadmill',\n",
       " 735: 'mud',\n",
       " 736: 'marching',\n",
       " 737: 'magic',\n",
       " 738: 'musical',\n",
       " 739: 'call',\n",
       " 740: 'axe',\n",
       " 741: 'wine',\n",
       " 742: 'wallaby',\n",
       " 743: 'stirred',\n",
       " 744: 'seasons',\n",
       " 745: 'shown',\n",
       " 746: 'pulled',\n",
       " 747: 'amazing',\n",
       " 748: 'block',\n",
       " 749: 'next',\n",
       " 750: 'gate',\n",
       " 751: 'sat',\n",
       " 752: 'throws',\n",
       " 753: 'wagging',\n",
       " 754: 'toward',\n",
       " 755: 'bottles',\n",
       " 756: 'tried',\n",
       " 757: 'got',\n",
       " 758: 'shaking',\n",
       " 759: 'combing',\n",
       " 760: 'trees',\n",
       " 761: 'dragon',\n",
       " 762: 'individual',\n",
       " 763: 'cub',\n",
       " 764: 'stuffed',\n",
       " 765: 'painting',\n",
       " 766: 'uses',\n",
       " 767: 'peppers',\n",
       " 768: 'team',\n",
       " 769: 'new',\n",
       " 770: 'umbrella',\n",
       " 771: 'accident',\n",
       " 772: 'item',\n",
       " 773: 'pushed',\n",
       " 774: 'but',\n",
       " 775: 'dives',\n",
       " 776: 'you',\n",
       " 777: 'place',\n",
       " 778: 'yoga',\n",
       " 779: 'sushi',\n",
       " 780: 'cheetah',\n",
       " 781: 'removes',\n",
       " 782: 'motorbike',\n",
       " 783: 'any',\n",
       " 784: 'asleep',\n",
       " 785: 'sniffing',\n",
       " 786: 'held',\n",
       " 787: 'set',\n",
       " 788: 'bull',\n",
       " 789: 'parking',\n",
       " 790: 'arms',\n",
       " 791: '-rrb-',\n",
       " 792: 'searching',\n",
       " 793: 'flipping',\n",
       " 794: 'anyone',\n",
       " 795: 'fall',\n",
       " 796: 'pancake',\n",
       " 797: 'chased',\n",
       " 798: 'suit',\n",
       " 799: '-lrb-',\n",
       " 800: 'cucumbers',\n",
       " 801: 'dices',\n",
       " 802: 'newspaper',\n",
       " 803: 'bathroom',\n",
       " 804: 'meowing',\n",
       " 805: 'chimpanzee',\n",
       " 806: 'ginger',\n",
       " 807: 'clear',\n",
       " 808: 'filled',\n",
       " 809: 'book',\n",
       " 810: 'shotgun',\n",
       " 811: 'gym',\n",
       " 812: 'tiny',\n",
       " 813: 'tamil',\n",
       " 814: 'nails',\n",
       " 815: 'attacks',\n",
       " 816: 'shoe',\n",
       " 817: 'themselves',\n",
       " 818: 'take',\n",
       " 819: 'performs',\n",
       " 820: 'push',\n",
       " 821: 'metal',\n",
       " 822: 'cubs',\n",
       " 823: 'bathtub',\n",
       " 824: 'flips',\n",
       " 825: 'demonstrates',\n",
       " 826: 'sang',\n",
       " 827: 'sharpening',\n",
       " 828: 'onstage',\n",
       " 829: 'bowling',\n",
       " 830: 'sunglasses',\n",
       " 831: 'crossing',\n",
       " 832: 'cracks',\n",
       " 833: 'broth',\n",
       " 834: 'what',\n",
       " 835: 'turns',\n",
       " 836: 'talk',\n",
       " 837: 'hiding',\n",
       " 838: 'herbs',\n",
       " 839: 'bell',\n",
       " 840: 'flowers',\n",
       " 841: 'not',\n",
       " 842: 'help',\n",
       " 843: 'tap',\n",
       " 844: 'right',\n",
       " 845: 'udon',\n",
       " 846: 'pumpkin',\n",
       " 847: 'refrigerator',\n",
       " 848: 'clean',\n",
       " 849: 'vacuum',\n",
       " 850: 'thing',\n",
       " 851: 'speech',\n",
       " 852: 'raft',\n",
       " 853: 'rhino',\n",
       " 854: 'octopus',\n",
       " 855: 'donkey',\n",
       " 856: 'hard',\n",
       " 857: 'powder',\n",
       " 858: 'style',\n",
       " 859: 's',\n",
       " 860: 'toilet',\n",
       " 861: 'tray',\n",
       " 862: 'soldier',\n",
       " 863: 'cubes',\n",
       " 864: 'flip',\n",
       " 865: 'plants',\n",
       " 866: 'runway',\n",
       " 867: 'goes',\n",
       " 868: 'faucet',\n",
       " 869: 'moose',\n",
       " 870: 'prepared',\n",
       " 871: 'baking',\n",
       " 872: 'time',\n",
       " 873: 'cloth',\n",
       " 874: 'eyes',\n",
       " 875: 'perform',\n",
       " 876: 'parsley',\n",
       " 877: 'telling',\n",
       " 878: 'office',\n",
       " 879: 'appears',\n",
       " 880: 'between',\n",
       " 881: 'pilot',\n",
       " 882: 'quickly',\n",
       " 883: 'branch',\n",
       " 884: 'waving',\n",
       " 885: 'tearing',\n",
       " 886: 'teams',\n",
       " 887: 'costume',\n",
       " 888: 'shirt',\n",
       " 889: 'pig',\n",
       " 890: 'duck',\n",
       " 891: 'stuck',\n",
       " 892: 'asian',\n",
       " 893: 'hotel',\n",
       " 894: 'mushroom',\n",
       " 895: 'watches',\n",
       " 896: 'otter',\n",
       " 897: 'round',\n",
       " 898: 'serving',\n",
       " 899: 'couples',\n",
       " 900: 'mowing',\n",
       " 901: 'opened',\n",
       " 902: 'tomatoe',\n",
       " 903: 'slab',\n",
       " 904: 'been',\n",
       " 905: 'wok',\n",
       " 906: 'passing',\n",
       " 907: 'saying',\n",
       " 908: 'floating',\n",
       " 909: 'log',\n",
       " 910: 'audience',\n",
       " 911: 'skateboarding',\n",
       " 912: 'seasonings',\n",
       " 913: 'bun',\n",
       " 914: 'things',\n",
       " 915: 'before',\n",
       " 916: 'dolls',\n",
       " 917: 'toad',\n",
       " 918: 'comes',\n",
       " 919: 'talked',\n",
       " 920: 'chain',\n",
       " 921: 'just',\n",
       " 922: 'driven',\n",
       " 923: 'rolls',\n",
       " 924: 'styling',\n",
       " 925: 'shadow',\n",
       " 926: 'eyebrows',\n",
       " 927: 'during',\n",
       " 928: 'model',\n",
       " 929: 'beautiful',\n",
       " 930: 'speed',\n",
       " 931: 'colored',\n",
       " 932: 'aeroplane',\n",
       " 933: 'bar',\n",
       " 934: 'featuring',\n",
       " 935: 'crocodile',\n",
       " 936: 'pen',\n",
       " 937: 'drops',\n",
       " 938: 'nabeyaki',\n",
       " 939: 'squeezing',\n",
       " 940: 'sumo',\n",
       " 941: 'explaining',\n",
       " 942: 'rowing',\n",
       " 943: 'pink',\n",
       " 944: 'climb',\n",
       " 945: 'paddling',\n",
       " 946: 'rolled',\n",
       " 947: 'sticks',\n",
       " 948: 'peel',\n",
       " 949: 'beside',\n",
       " 950: 'really',\n",
       " 951: 'sunflower',\n",
       " 952: 'cover',\n",
       " 953: 'tying',\n",
       " 954: 'language',\n",
       " 955: 'step',\n",
       " 956: 'wheelie',\n",
       " 957: 'guinea',\n",
       " 958: 'chipmunk',\n",
       " 959: 'applies',\n",
       " 960: 'beer',\n",
       " 961: 'vehicle',\n",
       " 962: 'knives',\n",
       " 963: 'tornado',\n",
       " 964: 'strawberries',\n",
       " 965: 'training',\n",
       " 966: 'work',\n",
       " 967: 'went',\n",
       " 968: 'reporter',\n",
       " 969: 'christmas',\n",
       " 970: 'digging',\n",
       " 971: 'highway',\n",
       " 972: 'moved',\n",
       " 973: 'bottom',\n",
       " 974: 'goat',\n",
       " 975: 'circle',\n",
       " 976: 'shape',\n",
       " 977: 'doll',\n",
       " 978: 'sleep',\n",
       " 979: 'pancakes',\n",
       " 980: 'here',\n",
       " 981: 'finely',\n",
       " 982: 'salmon',\n",
       " 983: 'first',\n",
       " 984: 'flesh',\n",
       " 985: 'bouncing',\n",
       " 986: 'bulldog',\n",
       " 987: 'background',\n",
       " 988: 'tips',\n",
       " 989: 'wet',\n",
       " 990: 'great',\n",
       " 991: 'ups',\n",
       " 992: 'shaving',\n",
       " 993: 'both',\n",
       " 994: 'watering',\n",
       " 995: 'shower',\n",
       " 996: 'dress',\n",
       " 997: 'knocks',\n",
       " 998: 'tire',\n",
       " 999: 'luggage',\n",
       " 1000: 'fires',\n",
       " 1001: 'remote',\n",
       " ...}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_idict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"youtube2text_iccv15/train.pkl\", 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48780"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"youtube2text_iccv15/valid.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(path, 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-826b1c42685b>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-826b1c42685b>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    config = DD{'model': 'attention', 'random_seed': 1234, 'erase_history': True, 'attention': DD{'reload_': False,\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "config = DD{'model': 'attention', 'random_seed': 1234, 'erase_history': True, 'attention': DD{'reload_': False, \n",
    "                                                                                              'save_model_dir': 'Experiments/arctic-capgen-vid/test_non/', \n",
    "                                                                                              'from_dir': '', 'dataset': 'youtube2text', \n",
    "                                                                                              'video_feature': 'googlenet', 'dim_word': 468, 'ctx_dim': -1, \n",
    "                                                                                              'dim': 3518, 'n_layers_out': 1, 'n_layers_init': 0, \n",
    "                                                                                              'encoder_dim': 300, 'prev2out': True, 'ctx2out': True, 'patience': 20, 'max_epochs': 500, 'decay_c': 0.0001, 'alpha_entropy_r': 0.0, 'alpha_c': 0.70602, 'lrate': 0.0001, 'selector': True, 'n_words': 20000, 'maxlen': 30, 'optimizer': 'adadelta', 'clip_c': 10.0, 'batch_size': 64, 'valid_batch_size': 200, 'dispFreq': 10, 'validFreq': 2000, 'saveFreq': -1, 'sampleFreq': 100, 'metric': 'everything', 'use_dropout': True, 'K': 28, 'OutOf': None, 'verbose': True, 'debug': False}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "    args = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = expand(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DD{}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the configuration for training files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding train_model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(state, channel=None):\n",
    "    set_config(config, state)\n",
    "    train_from_scratch(config, state, channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_config(conf, args, add_new_key=False):\n",
    "    # add_new_key: if conf does not contain the key, creates it\n",
    "    for key in args:\n",
    "        if key != 'jobman':\n",
    "            v = args[key]\n",
    "            if isinstance(v, DD):\n",
    "                set_config(conf[key], v)\n",
    "            else:\n",
    "                if conf.has_key(key):\n",
    "                    conf[key] = convert_from_string(v)\n",
    "                elif add_new_key:\n",
    "                    # create a new key in conf\n",
    "                    conf[key] = convert_from_string(v)\n",
    "                else:\n",
    "                    raise KeyError(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_from_scratch(config, state, channel):\n",
    "    # Model options\n",
    "    save_model_dir = config[config.model].save_model_dir\n",
    "    if save_model_dir == 'current':\n",
    "        config[config.model].save_model_dir = './'\n",
    "        save_model_dir = './'\n",
    "        # to facilitate the use of cluster for multiple jobs\n",
    "        save_path = './model_config.pkl'\n",
    "    else:\n",
    "        # run locally, save locally\n",
    "        save_path = save_model_dir + 'model_config.pkl'\n",
    "    print('current save dir ',save_model_dir)\n",
    "    common.create_dir_if_not_exist(save_model_dir)\n",
    "\n",
    "    reload_ = config[config.model].reload_\n",
    "    if reload_:\n",
    "        print('preparing reload')\n",
    "        save_dir_backup = config[config.model].save_model_dir\n",
    "        from_dir_backup = config[config.model].from_dir\n",
    "        # never start retrain in the same folder\n",
    "        assert save_dir_backup != from_dir_backup\n",
    "        print('save dir ',save_dir_backup)\n",
    "        print('from_dir ',from_dir_backup)\n",
    "        print('setting current model config with the old one')\n",
    "        model_config_old = common.load_pkl(from_dir_backup+'/model_config.pkl')\n",
    "        set_config(config, model_config_old)\n",
    "        config[config.model].save_model_dir = save_dir_backup\n",
    "        config[config.model].from_dir = from_dir_backup\n",
    "        config[config.model].reload_ = True\n",
    "    if config.erase_history:\n",
    "        print('erasing everything in ',save_model_dir)\n",
    "        os.system('rm %s/*'%save_model_dir)\n",
    "    # for stdout file logging\n",
    "    #sys.stdout = Unbuffered(sys.stdout, state.save_model_path + 'stdout.log')\n",
    "    print('saving model config into %s'%save_path)\n",
    "    common.dump_pkl(config, save_path)\n",
    "    # Also copy back from config into state.\n",
    "    for key in config:\n",
    "        setattr(state, key, config[key])\n",
    "    model_type = config.model\n",
    "    print('Model Type: %s'%model_type)\n",
    "    print('Host:    %s' % socket.gethostname())\n",
    "    print('Command: %s' % ' '.join(sys.argv))\n",
    "    if config.model == 'attention':\n",
    "        model_attention.train_from_scratch(state, channel)\n",
    "    else:\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_config(config, state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DD{'model': 'attention', 'random_seed': 1234, 'erase_history': True, 'attention': DD{'reload_': False, 'save_model_dir': 'Experiments/arctic-capgen-vid/test_non/', 'from_dir': '', 'dataset': 'youtube2text', 'video_feature': 'googlenet', 'dim_word': 468, 'ctx_dim': -1, 'dim': 3518, 'n_layers_out': 1, 'n_layers_init': 0, 'encoder_dim': 300, 'prev2out': True, 'ctx2out': True, 'patience': 20, 'max_epochs': 500, 'decay_c': 0.0001, 'alpha_entropy_r': 0.0, 'alpha_c': 0.70602, 'lrate': 0.0001, 'selector': True, 'n_words': 20000, 'maxlen': 30, 'optimizer': 'adadelta', 'clip_c': 10.0, 'batch_size': 64, 'valid_batch_size': 200, 'dispFreq': 10, 'validFreq': 2000, 'saveFreq': -1, 'sampleFreq': 100, 'metric': 'everything', 'use_dropout': True, 'K': 28, 'OutOf': None, 'verbose': True, 'debug': False}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DD{}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current save dir  Experiments/arctic-capgen-vid/test_non/\n",
      "Experiments/arctic-capgen-vid/test_non/ already exists!\n",
      "erasing everything in  Experiments/arctic-capgen-vid/test_non/\n",
      "saving model config into Experiments/arctic-capgen-vid/test_non/model_config.pkl\n",
      "Model Type: attention\n",
      "Host:    groot-groot\n",
      "Command: /home/himansh/env/lib/python3.7/site-packages/ipykernel_launcher.py -f /run/user/1005/jupyter/kernel-c02e743c-38d6-44de-9250-788960e4ed09.json\n",
      "training an attention model\n",
      "Loading data\n",
      "loading youtube2text googlenet features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/Seagate_4TB1/himansh/Anirudh/arctic-capgen-vid/model_attention.py:37: UserWarning: Feeding context to output directly seems to hurt.\n",
      "  warnings.warn('Feeding context to output directly seems to hurt.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uneven minibath chunking, overall 64, last one 12\n",
      "uneven minibath chunking, overall 200, last one 91\n",
      "uneven minibath chunking, overall 200, last one 168\n",
      "init params\n",
      "no lstm on ctx\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-231874aefd32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_from_scratch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-6d29c63e6748>\u001b[0m in \u001b[0;36mtrain_from_scratch\u001b[0;34m(config, state, channel)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Command: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'attention'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mmodel_attention\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_from_scratch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Seagate_4TB1/himansh/Anirudh/arctic-capgen-vid/model_attention.py\u001b[0m in \u001b[0;36mtrain_from_scratch\u001b[0;34m(state, channel)\u001b[0m\n\u001b[1;32m   1303\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'training an attention model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchannel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1305\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1306\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'training time in total %.4f sec'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Seagate_4TB1/himansh/Anirudh/arctic-capgen-vid/model_attention.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, random_seed, dim_word, ctx_dim, dim, n_layers_out, n_layers_init, encoder, encoder_dim, prev2out, ctx2out, patience, max_epochs, dispFreq, decay_c, alpha_c, alpha_entropy_r, lrate, selector, n_words, maxlen, optimizer, clip_c, batch_size, valid_batch_size, save_model_dir, validFreq, saveFreq, sampleFreq, metric, dataset, video_feature, use_dropout, reload_, from_dir, K, OutOf, verbose, debug)\u001b[0m\n\u001b[1;32m    911\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'init params'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 913\u001b[0;31m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m         \u001b[0;31m# reloading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Seagate_4TB1/himansh/Anirudh/arctic-capgen-vid/model_attention.py\u001b[0m in \u001b[0;36minit_params\u001b[0;34m(self, options)\u001b[0m\n\u001b[1;32m    425\u001b[0m         params = self.get_layer('lstm_cond')[0](options, params, prefix='decoder',\n\u001b[1;32m    426\u001b[0m                                            \u001b[0mnin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dim_word'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dim'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m                                            dimctx=ctx_dim)\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0;31m# readout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Seagate_4TB1/himansh/Anirudh/arctic-capgen-vid/model_attention.py\u001b[0m in \u001b[0;36mparam_init_lstm_cond\u001b[0;34m(self, options, params, prefix, nin, dim, dimctx)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;31m# LSTM to LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         U = numpy.concatenate([ortho_weight(dim),\n\u001b[0m\u001b[1;32m    197\u001b[0m                                \u001b[0mortho_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                                \u001b[0mortho_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Seagate_4TB1/himansh/Anirudh/arctic-capgen-vid/common.py\u001b[0m in \u001b[0;36mortho_weight\u001b[0;34m(ndim)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \"\"\"\n\u001b[1;32m    120\u001b[0m     \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrng_numpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/lib/python3.7/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv)\u001b[0m\n\u001b[1;32m   1442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m         \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->DdD'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->ddd'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1444\u001b[0;31m         \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1445\u001b[0m         \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1446\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_realType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_from_scratch(config=config, state=state, channel=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "    save_model_dir = config[config.model].save_model_dir\n",
    "    if save_model_dir == 'current':\n",
    "        config[config.model].save_model_dir = './'\n",
    "        save_model_dir = './'\n",
    "        # to facilitate the use of cluster for multiple jobs\n",
    "        save_path = './model_config.pkl'\n",
    "    else:\n",
    "        # run locally, save locally\n",
    "        save_path = save_model_dir + 'model_config.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Experiments/arctic-capgen-vid/test_non/'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "    reload_ = config[config.model].reload_\n",
    "    if reload_:\n",
    "        print('preparing reload')\n",
    "        save_dir_backup = config[config.model].save_model_dir\n",
    "        from_dir_backup = config[config.model].from_dir\n",
    "        # never start retrain in the same folder\n",
    "        assert save_dir_backup != from_dir_backup\n",
    "        print('save dir ',save_dir_backup)\n",
    "        print('from_dir ',from_dir_backup)\n",
    "        print('setting current model config with the old one')\n",
    "        model_config_old = common.load_pkl(from_dir_backup+'/model_config.pkl')\n",
    "        set_config(config, model_config_old)\n",
    "        config[config.model].save_model_dir = save_dir_backup\n",
    "        config[config.model].from_dir = from_dir_backup\n",
    "        config[config.model].reload_ = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "erasing everything in  Experiments/arctic-capgen-vid/test_non/\n"
     ]
    }
   ],
   "source": [
    "    if config.erase_history:\n",
    "        print('erasing everything in ',save_model_dir)\n",
    "        os.system('rm %s/*'%save_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "    for key in config:\n",
    "        setattr(state, key, config[key])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DD{'model': 'attention', 'random_seed': 1234, 'erase_history': True, 'attention': DD{'reload_': False, 'save_model_dir': 'Experiments/arctic-capgen-vid/test_non/', 'from_dir': '', 'dataset': 'youtube2text', 'video_feature': 'googlenet', 'dim_word': 468, 'ctx_dim': -1, 'dim': 3518, 'n_layers_out': 1, 'n_layers_init': 0, 'encoder_dim': 300, 'prev2out': True, 'ctx2out': True, 'patience': 20, 'max_epochs': 500, 'decay_c': 0.0001, 'alpha_entropy_r': 0.0, 'alpha_c': 0.70602, 'lrate': 0.0001, 'selector': True, 'n_words': 20000, 'maxlen': 30, 'optimizer': 'adadelta', 'clip_c': 10.0, 'batch_size': 64, 'valid_batch_size': 200, 'dispFreq': 10, 'validFreq': 2000, 'saveFreq': -1, 'sampleFreq': 100, 'metric': 'everything', 'use_dropout': True, 'K': 28, 'OutOf': None, 'verbose': True, 'debug': False}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention\n"
     ]
    }
   ],
   "source": [
    "    model_type = config.model\n",
    "    print(model_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing train_from_scratch from model_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = None\n",
    "hostname = socket.gethostname()\n",
    "lscratch_dir = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "    t0 = time.time()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(object):\n",
    "    \n",
    "    def __init__(self, channel = None):\n",
    "        # These are the different functions that perform the initialization of parameters of their respective layers\n",
    "        self.layers = {\n",
    "            'ff': ('self.param_init_ff_layer', 'self.fflayer'),\n",
    "            'lstm': ('self.param_init_lstm', 'self.lstm_layer'),\n",
    "            'lstm_cond': ('self.param_init_lstm_cond', 'self.lstm_cond_layer'),\n",
    "        }\n",
    "        self.channel = channel\n",
    "        \n",
    "    def get_layer(self, name):\n",
    "        \"\"\"\n",
    "        Part of the reason the init is very slow is because,\n",
    "        the layer's constructor is called even when it isn't needed\n",
    "        \"\"\"\n",
    "        fns = self.layers[name]\n",
    "        return eval((fns[0]), eval(fns[1]))\n",
    "        \n",
    "        \n",
    "    def load_params(self, path, params):\n",
    "        # load params from disk\n",
    "        pp = numpy.load(path)\n",
    "        for kk, vv in params.items():\n",
    "            if kk not in pp:\n",
    "                raise Warning('%s is not in the archive'%kk)\n",
    "            params[kk] = pp[kk]\n",
    "            \n",
    "        return params\n",
    "    \n",
    "    def init_tparams(self, params, force_cpu=False):\n",
    "        # initialize Theano shared variables according to the initial parameters\n",
    "        tparams = OrderedDict()\n",
    "        for kk, pp in params.items():\n",
    "            if force_cpu:\n",
    "                tparams[kk] = theano.tensor._shared(params[kk], name=kk)\n",
    "            else:\n",
    "                tparams[kk] = theano.shared(params[kk], name=kk)\n",
    "        return tparams\n",
    "    \n",
    "    def param_init_fflayer(self, options, params, prefix = 'ff', nin = None, nout = None):\n",
    "        if nin == None:\n",
    "            nin = options['dim_proj']\n",
    "        if nout == None:\n",
    "            nout = options['dim_proj']\n",
    "            \n",
    "        params[_p(prefix, 'W')] = norm_weight(nin, nout, scale=0.01)\n",
    "        params[_p(prefix, 'b')] = np.zeros((nout,)).astype('float32')\n",
    "        \n",
    "        return params\n",
    "    \n",
    "    def fflayer(self, tparams, state_below, options, prefix='rconv', activ='lambda x: tensor.tanh(x)', **kwargs):\n",
    "        return eval(activ)(tensor.dot(state_below, tparams[_p(prefix,'W')])+tparams[_p(prefix,'b')])\n",
    "    \n",
    "    # LSTM layer\n",
    "    def param_init_lstm(self, options, params, prefix = None, nin= None, dim = None):\n",
    "        assert prefix is not None\n",
    "        \n",
    "        if nin == None:\n",
    "            nin = options['dim_proj']\n",
    "        \n",
    "        if dim == None:\n",
    "            dim = options['dim_proj']\n",
    "            \n",
    "        # Stack the weight matricies for faster dot prods\n",
    "        # norm_weight initializes the weights of the matrix by random values\n",
    "        W = np.concatenate([norm_weight(nin, dim), norm_weight(nin=nin,dim), norm_weight(nin=nin, dim=dim),\n",
    "                           norm_weight(nin=nin, dim=dim)], axis = 1)\n",
    "        \n",
    "        params[_p(prefix,'W')] = W\n",
    "                \n",
    "        U = numpy.concatenate([ortho_weight(dim),\n",
    "                               ortho_weight(dim),\n",
    "                               ortho_weight(dim),\n",
    "                               ortho_weight(dim)], axis=1)\n",
    "        params[_p(prefix,'U')] = U\n",
    "        params[_p(prefix,'b')] = numpy.zeros((4 * dim,)).astype('float32')\n",
    "        \n",
    "        return params\n",
    "    \n",
    "    # Implementation of lstm fprop\n",
    "    def lstm_layer(self, tparams, state_below, options, prefix='lstm', mask = None, forget = False, use_noise = None,\n",
    "                  trng = None, **kwargs):\n",
    "        \n",
    "        nsteps = state_below.shape[0]\n",
    "        dim = tparams[_p(prefix, 'U')].shape[0]\n",
    "        \n",
    "        if state_below.ndim == 3:\n",
    "            n_samples = state_below.shape[1]\n",
    "            init_state = tensor.alloc(0., n_samples, dim)\n",
    "            init_memory = tensor.alloc(0., n_samples, dim)\n",
    "        else:\n",
    "            n_samples = 1\n",
    "            init_state = tensor.alloc(0., dim)\n",
    "            init_memory = tensor.alloc(0., dim)\n",
    "            \n",
    "        if mask == None:\n",
    "            mask = tensor.alloc(1., state_below.shape[0], 1)\n",
    "            \n",
    "        def _slice(_x, n, dim):\n",
    "            if _x.ndim == 3:\n",
    "                return _x[:, :, n*dim:(n+1)*dim]\n",
    "            elif _x.ndim == 2:\n",
    "                return _x[:, n*dim:(n+1)*dim]\n",
    "            return _x[n*dim:(n+1)*dim]\n",
    "        \n",
    "        def _step(m_, x_, h_, c_, U, b):\n",
    "            preact = tensor.dot(h_, U)\n",
    "            preact += x_\n",
    "            preact += b\n",
    "\n",
    "            i = tensor.nnet.sigmoid(_slice(preact, 0, dim))\n",
    "            f = tensor.nnet.sigmoid(_slice(preact, 1, dim))\n",
    "            o = tensor.nnet.sigmoid(_slice(preact, 2, dim))\n",
    "            c = tensor.tanh(_slice(preact, 3, dim))\n",
    "\n",
    "            if forget:\n",
    "                f = T.zeros_like(f)\n",
    "            c = f * c_ + i * c\n",
    "            h = o * tensor.tanh(c)\n",
    "            if m_.ndim == 0:\n",
    "                # when using this for minibatchsize=1\n",
    "                h = m_ * h + (1. - m_) * h_\n",
    "                c = m_ * c + (1. - m_) * c_\n",
    "            else:\n",
    "                h = m_[:,None] * h + (1. - m_)[:,None] * h_\n",
    "                c = m_[:,None] * c + (1. - m_)[:,None] * c_\n",
    "            return h, c, i, f, o, preact\n",
    "\n",
    "        state_below = tensor.dot(state_below, tparams[_p(prefix, 'W')]) + tparams[_p(prefix, 'b')]\n",
    "        U = tparams[_p(prefix, 'U')]\n",
    "        b = tparams[_p(prefix, 'b')]\n",
    "        rval, updates = theano.scan(\n",
    "            _step,\n",
    "            sequences=[mask, state_below],\n",
    "            non_sequences=[U,b],\n",
    "            outputs_info = [init_state, init_memory, None, None, None, None],\n",
    "            name=_p(prefix, '_layers'),\n",
    "            n_steps=nsteps,\n",
    "            strict=True,\n",
    "            profile=False)\n",
    "        return rval\n",
    "    \n",
    "    # Conditional LSTM layer with Attention\n",
    "    def param_init_lstm_cond(self, options, params, prefix='lstm_cond', nin=None, dim=None, dimctx = None):\n",
    "        if nin == None:\n",
    "            nin = options['dim']\n",
    "        if dim == None:\n",
    "            dim = options['dim']\n",
    "        if dimctx == None:\n",
    "            dimctx = options['dim']\n",
    "            \n",
    "        # input to LSTM\n",
    "        W = numpy.concatenate([norm_weight(nin,dim),\n",
    "                               norm_weight(nin,dim),\n",
    "                               norm_weight(nin,dim),\n",
    "                               norm_weight(nin,dim)], axis=1)\n",
    "        params[_p(prefix,'W')] = W\n",
    "\n",
    "        # LSTM to LSTM\n",
    "        U = numpy.concatenate([ortho_weight(dim),\n",
    "                               ortho_weight(dim),\n",
    "                               ortho_weight(dim),\n",
    "                               ortho_weight(dim)], axis=1)\n",
    "        params[_p(prefix,'U')] = U\n",
    "        \n",
    "        # Bias to LSTM\n",
    "        params[_p(prefix, 'b')] = np.zeros((4 * dim,)).astype('float32')\n",
    "        \n",
    "        # Context to LSTM\n",
    "        Wc = norm_weight(dimctx, dim*4)\n",
    "        params[_p(prefix, 'Wc')] = Wc\n",
    "        \n",
    "        # attention: context -> hidden\n",
    "        Wc_att = norm_weight(dimctx, ortho=False)\n",
    "        params[_p(prefix,'Wc_att')] = Wc_att\n",
    "\n",
    "        # attention: LSTM -> hidden\n",
    "        Wd_att = norm_weight(dim,dimctx)\n",
    "        params[_p(prefix,'Wd_att')] = Wd_att\n",
    "\n",
    "        # attention: hidden bias\n",
    "        b_att = numpy.zeros((dimctx,)).astype('float32')\n",
    "        params[_p(prefix,'b_att')] = b_att\n",
    "        \n",
    "        # attention:\n",
    "        U_att = norm_weight(dimctx,1)\n",
    "        params[_p(prefix,'U_att')] = U_att\n",
    "        c_att = numpy.zeros((1,)).astype('float32')\n",
    "        params[_p(prefix, 'c_tt')] = c_att\n",
    "\n",
    "        if options['selector']:\n",
    "            # attention: selector\n",
    "            W_sel = norm_weight(dim, 1)\n",
    "            params[_p(prefix, 'W_sel')] = W_sel\n",
    "            b_sel = numpy.float32(0.)\n",
    "            params[_p(prefix, 'b_sel')] = b_sel\n",
    "\n",
    "        return params\n",
    "    \n",
    "    def lstm_cond_layer(self, tparams, state_below, options, prefix = 'lstm', mask= None, context = None, \n",
    "                       one_step = False, init_memory = None, init_state = None, trng = None, use_noise = None, \n",
    "                       mode = None, **kwargs):\n",
    "        \n",
    "        # state_below (t, m, dim_word), or (m, dim_word) in sampling\n",
    "        # mask (t, m)\n",
    "        # context (m, f, dim_ctx), or (f, dim_word) in sampling\n",
    "        # init_memory, init_state (m, dim)\n",
    "        assert context, 'Context must be provided'\n",
    "\n",
    "        if one_step:\n",
    "            \n",
    "            assert init_memory, 'previous memory must be provided'\n",
    "            assert init_state, 'previous state must be provided'\n",
    "    \n",
    "        nsteps = state_below.shape[0]\n",
    "        \n",
    "        if state_below.ndim == 3:\n",
    "            n_samples = state_below.shape[1]\n",
    "        else:\n",
    "            n_samples = 1\n",
    "            \n",
    "        # mask\n",
    "        if mask == None:\n",
    "            mask = tensor.alloc(1., state_below.shape[0], 1)\n",
    "        \n",
    "        dim = tparams[_p(prefix, 'U')].shape[0]\n",
    "        \n",
    "        # initial/previous state\n",
    "        if init_state == None:\n",
    "            init_state = tensor.alloc(0., n_samples, dim)\n",
    "        \n",
    "        # initial/previous memory\n",
    "        if init_memory == None:\n",
    "            init_memory = tensor.alloc(0., n_samples, dim)\n",
    "            \n",
    "        # Projected context\n",
    "        pctx_ = tensor.dot(context, tparams[_p(prefix, 'Wc_att')]) + tparams[_p(prefix, 'b_att')]\n",
    "        \n",
    "        if one_step:\n",
    "            pctx_ = T.addbroadcast(pctx_, 0)\n",
    "            \n",
    "        # projected x\n",
    "        state_below = tensor.dot(state_below, tparams[_p(prefix, 'W')]) + tparams[_p(prefix, 'b')]\n",
    "        \n",
    "        Wd_att = tparams[_p(prefix, 'Wd_att')]\n",
    "        U_att = tparams[_p(prefix, 'U_att')]\n",
    "        c_att = tparams[_p(prefix), 'c_tt']\n",
    "        \n",
    "        if options['selector']:\n",
    "            W_sel = tparams[_p(prefix, 'W_sel')]\n",
    "            b_sel = tparams[_p(prefix,'b_sel')]\n",
    "        else:\n",
    "            W_sel = T.alloc(0., 1)\n",
    "            b_sel = T.alloc(0., 1)\n",
    "        \n",
    "        U = tparams[_p(prefix, 'U')]\n",
    "        Wc = tparams[_p(prefix, 'Wc')]\n",
    "        \n",
    "        def _slice(_x, n, dim):\n",
    "            if _x.ndim == 3:\n",
    "                return _x[:, :, n*dim:(n+1)*dim]\n",
    "            return _x[:, n*dim:(n+1)*dim]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
